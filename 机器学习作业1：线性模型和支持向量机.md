# 机器学习作业1：线性模型和支持向量机

-----

刘明礼 无07 2020010809

-----

[TOC]

## 2. 线性模型与梯度下降

### 2.1 特征归一化

[0, 1]归一化方法：$x_{scale}=\frac{x-x_{min}}{x_{max}-x_{min}}$

代码如下：

```python
    train_max = np.max(train, axis=0)
    train_min = np.min(train, axis=0)
    train_normalized = (train - train_min) / (train_max - train_min)
    test_normalized = (test - train_min) / (train_max - train_min)
```

### 2.2 目标函数与梯度

#### 2.2.1


$$
\begin{aligned} 
J(\theta) &= \frac{1}{m}\sum_{i=1}^{m}(h_{\theta}(x_i)-y_i)^2+\lambda\theta^T\theta\\ 
&= \frac{1}{m}\sum_{i=1}^{m}(\theta^T x_i-y_i)^2+\lambda\theta^T\theta\\ 
&= \frac{1}{m}(X\theta-y)^T(X\theta-y)+\lambda\theta^T\theta
\end{aligned}
$$

#### 2.2.2

将以上公式写成代码：

```python
    num_features = X.shape[1]
    num_instances = y.shape[0]
    loss = np.dot((np.dot(X, theta.reshape(num_features, 1)) - y.reshape(num_instances, 1)).T, np.dot(X, theta.reshape(num_features, 1)) - y.reshape(num_instances, 1)) / num_instances + lambda_reg * np.dot((theta.reshape(num_features, 1)).T, theta.reshape(num_features, 1))
    return loss.squeeze()
```

#### 2.2.3

$$
\nabla_{\theta}J = \frac{2}{m}X^T(X \theta - y)+2\lambda\theta
$$

#### 2.2.4

将以上公式写成代码：

```python
    num_features = X.shape[1]
    num_instances = y.shape[0]
    grad = 2 / num_instances * np.dot(X.T, (np.dot(X, theta.reshape(num_features, 1)) - y.reshape(num_instances, 1))) + 2 * lambda_reg * theta.reshape(num_features, 1)
    grad = grad.squeeze()
    return grad
```

#### 2.2.5

通过NumPy的广播机制与np.apply_along_axis函数求出损失函数函数不同方向的方向导数，再与梯度进行比较

```python
    H = np.eye(num_features)
    theta_lim_p = theta + epsilon * H
    theta_lim_n = theta - epsilon * H
    loss_lim_p = np.apply_along_axis(lambda x:compute_regularized_square_loss(X, y, x, lambda_reg), 1, theta_lim_p)
    loss_lim_n = np.apply_along_axis(lambda x:compute_regularized_square_loss(X, y, x, lambda_reg), 1, theta_lim_n)
    approx_grad = ((loss_lim_p - loss_lim_n) / 2 / epsilon).reshape(num_features, 1)
    err = np.dot((approx_grad.reshape(num_features, 1) - true_gradient.reshape(num_features, 1)).T,approx_grad.reshape(num_features, 1) - true_gradient.reshape(num_features, 1))
    # print("True gradient:")
    # print(true_gradient)
    # print("approx:")
    # print(approx_grad)
    # print(err)
    if err < tolerance:
        return True
    else:
        return False
```

参考：[numpy.apply_along_axis — NumPy v2.0.dev0 Manual](https://numpy.org/devdocs/reference/generated/numpy.apply_along_axis.html#numpy-apply-along-axis)

#### 2.2.6

- [ ] TODO

### 2.3 梯度下降

#### 2.3.1

$$
J(\theta+\eta h)-J(\theta) \approx \eta h^T\nabla_{\theta}J
$$

$h$为负梯度方向时下降最快

#### 2.3.2

$$
\theta \leftarrow \theta - \eta \nabla_{\theta}J
$$

#### 2.3.3

```python
    for i in range(num_iter):
        loss_hist[i] = compute_regularized_square_loss(X, y, theta_hist[i], lambda_reg)
        grad = compute_regularized_square_loss_gradient(X, y, theta_hist[i], lambda_reg)
        # if grad_checker(X, y, theta, lambda_reg):
        #     print("iter"+str(i)+",grad check succeed")
        # else:
        #     print("iter"+str(i)+",grad check failed")
        theta_hist[i+1] = theta_hist[i] - alpha * grad
    return theta_hist, loss_hist
```

#### 2.3.4

lambda设为0，即无正则化情况下，在main()函数中添加代码进行画图：

```python
    #GD不同步长下损失函数随迭代次数的变化(lambda=0)
    print("GD不同步长下损失函数随迭代次数的变化")
    plt.figure()
    for alpha in [0.1, 0.5, 0.05, 0.01]:
        _, loss_hist = batch_grad_descent(X_train, y_train, 0, alpha)
        plt.plot(loss_hist, label="alpha="+str(alpha))
    plt.legend()
    plt.xlabel("iter"), plt.ylabel("loss")
    plt.ylim((0,12))    #alpha=0.1或0.5时损失函数发散，限制y轴范围
    plt.title("loss curve under different alpha in GD (lambda = 0)")
    plt.savefig("GD不同步长下损失函数随迭代次数的变化.jpg")
```

画出图像如下：

![GD不同步长下损失函数随迭代次数的变化](D:\THU\机器学习\ml2023_hw1\ml2023_hw1\sgd\GD不同步长下损失函数随迭代次数的变化.jpg)

可以看到，当alpha=0.1和alpha=0.5时，步长过大导致损失函数发散；

当alpha=0.05时，收敛最快；而步长进一步减小至0.01时，收敛速度减慢

### 2.4 随机梯度下降

#### 2.4.1 

$$
\begin{flalign} 
&令X_i = 
\begin{pmatrix}
x_{i1}^T\\
x_{i2}^T\\
\cdots\\
x_{in}^T\\
\end{pmatrix},
y_i = 
\begin{pmatrix}
y_{i1}^T\\
y_{i2}^T\\
\cdots\\
y_{in}^t\\
\end{pmatrix}
\\
&则与2.2.3相似：\\
&\nabla J_{SGD}(\theta) = \frac{2}{n}X_i^T(X_i \theta - y_i)+2\lambda\theta
\end{flalign}
$$

#### 2.4.2

$$
\begin{aligned}
\mathbb{E}_{i_{1},i_{2},\cdots,i_{n}}[\nabla J_{SGD}(\theta)] 
&=\mathbb{E}_{i_{1},i_{2},\cdots,i_{n}}[\frac{2}{n}X_i^T(X_i \theta - y_i)+2\lambda\theta] \\
&=\frac{2}{n}\mathbb{E}_{i_{1},i_{2},\cdots,i_{n}}[X_i^T(X_i \theta - y_i)]+2\lambda\theta	\\
&=\frac{2}{n}\mathbb{E}_{i_{1},i_{2},\cdots,i_{n}}[\sum_{k=1}^{n}(x_{ik}^T\theta-y_{ik})x_{ik}]+2\lambda\theta	\\
&=\frac{2}{n}\sum_{k=1}^n\mathbb{E}_{i_{1},i_{2},\cdots,i_{n}}[(x_{ik}^T\theta-y_{ik})x_{ik}]+2\lambda\theta	\\
&=\frac{2}{n}\sum_{k=1}^{n}\sum_{j=1}^{m}P(i_k=j)(x_j^T\theta-y_j)x_j+2\lambda\theta	\\
\end{aligned}
$$

$$
\begin{flalign}
&其中P(i_k=j)为i_k=j的概率	\\
&在n\ll m且i_k从\{1,2,\cdots,m\}中独立同分布采样时有	\\
&P(i_k=j)=\frac{1}{m} ,\forall k=1,2,\cdots,n \\
&因此有
\end{flalign}
$$

$$
\begin{aligned}
\mathbb{E}_{i_{1},i_{2},\cdots,i_{n}}[\nabla J_{SGD}(\theta)] 
&=\frac{2}{n}\sum_{k=1}^{n}\sum_{j=1}^{m}\frac{1}{m}(x_j^T\theta-y_j)x_j+2\lambda\theta	\\
&=\frac{2}{n}\cdot n\cdot\frac{1}{m}\sum_{j=1}^{m}(x_j^T\theta-y_j)x_j+2\lambda\theta	\\
&=\frac{2}{m}\sum_{i=1}^{m}(x_i^T\theta-y_i)x_i+2\lambda\theta	\\
&=\frac{2}{m}X^T(X\theta-y)+2\lambda\theta	\\
&=\nabla_{\theta}J
\end{aligned}
$$

#### 2.4.3

使用np.random.choice函数进行批的随机选取

具体代码如下：

```python
    for i in range(num_iter):
        current_alpha = compute_current_alpha(alpha, i+1)
        batch_index = np.random.choice(num_instances, batch_size)
        grad = compute_regularized_square_loss_gradient(X_train[batch_index], y_train[batch_index], theta_hist[i], lambda_reg)
        theta_hist[i+1] = theta_hist[i] - current_alpha * grad
        loss_hist[i] = compute_regularized_square_loss(X_train[batch_index], y_train[batch_index], theta_hist[i+1], lambda_reg)
        validation_hist[i] = compute_regularized_square_loss(X_test, y_test, theta_hist[i+1], 0)

    return theta_hist, loss_hist, validation_hist
```

#### 2.4.4

三种步长策略：alpha_list = [0.01, "0.05/sqrt(t)", "0.05/t"]

批大小分别选取[1, 5, 10, 20, 50, 100]

具体代码如下：

```python
    #SGD不同批大小训练曲线发生的变化
    print("SGD不同批大小训练曲线发生的变化")
    #plt.figure()
    alpha_list = [0.01, "0.05/sqrt(t)", "0.05/t"]
    for batch_size in [1, 5, 10, 20, 50, 100]:
        plt.figure()
        for i in range(3):
            alpha = alpha_list[i]
            _, loss_hist, validation_hist = stochastic_grad_descent(X_train, y_train, X_test, y_test, 0, alpha=alpha, num_iter=1000, batch_size=batch_size)
            plt.subplot(1, 2, 1)
            plt.plot(loss_hist, label="alpha={}".format(alpha))
            plt.legend()
            plt.xlabel("iter",loc='right')
            plt.ylabel("train loss")
            plt.ylim((0,max(loss_hist)))
            plt.subplot(1, 2, 2)
            plt.plot(validation_hist, label="alpha={}".format(alpha))
            plt.legend()
            plt.xlabel("iter",loc='right')
            plt.ylabel("validation loss")
            plt.ylim((0,max(validation_hist)))
        plt.suptitle("batch size = {}".format(batch_size))
        plt.savefig("SGD不同批大小训练曲线发生的变化(batch size={}).jpg".format(batch_size))
```

结果如下：

![](D:\THU\机器学习\ml2023_hw1\ml2023_hw1\sgd\SGD不同批大小训练曲线发生的变化(batch size=1).jpg)

![](D:\THU\机器学习\ml2023_hw1\ml2023_hw1\sgd\SGD不同批大小训练曲线发生的变化(batch size=5).jpg)

![](D:\THU\机器学习\ml2023_hw1\ml2023_hw1\sgd\SGD不同批大小训练曲线发生的变化(batch size=10).jpg)

![](D:\THU\机器学习\ml2023_hw1\ml2023_hw1\sgd\SGD不同批大小训练曲线发生的变化(batch size=20).jpg)

![](D:\THU\机器学习\ml2023_hw1\ml2023_hw1\sgd\SGD不同批大小训练曲线发生的变化(batch size=50).jpg)

![](D:\THU\机器学习\ml2023_hw1\ml2023_hw1\sgd\SGD不同批大小训练曲线发生的变化(batch size=100).jpg)

可以看到：

- 批大小越小，收敛时噪声越明显
- 不同步长策略的收敛速度不同，本次对比中alpha=0.01时损失函数下降最快，而alpha=0.05/t时可能由于步长衰减过快导致下降速度过慢。但同时不同步长策略导致的收敛时的噪声也不同，本次对比中alpha=0.01时噪声较大。推测是固定步长在多次迭代后仍会因批上算出的梯度与实际梯度存在差异而不断浮动，使其不易收敛至一个确定值
- 训练集上的损失函数相比验证集有着极大的噪声

### 2.5 模型选择
